{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. State the question and determine the required data\n",
    "\n",
    "# Teatro Real HVAC System Data-based Simulator Model Ver. 0\n",
    "# The outputs are intended to provide the fitness score to the MO algorithm:\n",
    "#   - Comfort, Consumed energy, Cost & Performance (COP)\n",
    "#   - Variance of temperature and time before the show when the goal is reached\n",
    "# The model is to simulate the start up of the engines until Tr reaches T0\n",
    "# (It can also work with any event that requires a change in the capacities)\n",
    "# Necessary inputs are each chiller capacity (%), the OM, and OM' start time\n",
    "\n",
    "# Project framework libraries selection\n",
    "#   Jupyter notebook Server, Ver. 5.7.8\n",
    "#   Current Kernel Information: Python 3.7.3\n",
    "\n",
    "# Python core - Vectors, Matrices & Dates\n",
    "#   - Python 3.7.6rc1 \n",
    "#   - NumPy 1.17\n",
    "#   - pandas 0.25.3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# Data analysis:\n",
    "#   - To split dataset\n",
    "#   - To build Random Forest Regressor\n",
    "#   - To build MLP\n",
    "#   - For Grid search, tuning hyper-parameters of an estimator \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "\n",
    "# Figures: Heat maps, Boxplots\n",
    "#   - Matplotlib 3.1.1\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Unlimited # of displayed columns\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Acquire data in accessible format. Read tables from Excel\n",
    "\n",
    "# Differentiate data directories\n",
    "data_in = \"./input/\"\n",
    "data_out = \"./output/\"\n",
    "\n",
    "# Acquire data from Read Teatro Real database\n",
    "#   - Info from sensors in Production:                hvacs\n",
    "#   - Temperature sensed in zones, except auditorium: zones\n",
    "#   - Temperatures in auditorium & adjacent in shows: shows\n",
    "hvacs_raw = pd.read_excel(data_in + 'tr_hvacs.xlsx')\n",
    "zones_raw = pd.read_excel(data_in + 'tr_zones.xlsx')\n",
    "shows_raw = pd.read_excel(data_in + 'tr_shows.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>h_Pe_Trf2</th>\n",
       "      <th>h_Pe_Trf3</th>\n",
       "      <th>h_Pe_Trf4</th>\n",
       "      <th>h_Pe_Trf5</th>\n",
       "      <th>h_Pe_Tot</th>\n",
       "      <th>h_per6</th>\n",
       "      <th>h_CtrlCool</th>\n",
       "      <th>h_CtrlHeat</th>\n",
       "      <th>h_Cap_ChF</th>\n",
       "      <th>h_Cap_ChC</th>\n",
       "      <th>h_COPInst_ChF</th>\n",
       "      <th>h_COPInst_ChC</th>\n",
       "      <th>h_Pe_ChF</th>\n",
       "      <th>h_Pe_ChC</th>\n",
       "      <th>h_Tr_ChC</th>\n",
       "      <th>h_Tr_ChF</th>\n",
       "      <th>h_Text</th>\n",
       "      <th>h_Cap_Ch1</th>\n",
       "      <th>h_Cap_Ch2</th>\n",
       "      <th>h_COPInst_Ch1</th>\n",
       "      <th>h_COPInst_Ch2</th>\n",
       "      <th>h_Pe_Ch1</th>\n",
       "      <th>h_Pe_Ch2</th>\n",
       "      <th>h_TIn_Twr1</th>\n",
       "      <th>h_TOut_Twr1</th>\n",
       "      <th>h_TIn_Twr2</th>\n",
       "      <th>h_TOut_Twr2</th>\n",
       "      <th>h_COPMq_Ch1</th>\n",
       "      <th>h_COPMq_Ch2</th>\n",
       "      <th>h_COPMq_ChC</th>\n",
       "      <th>h_COPMq_ChF</th>\n",
       "      <th>h_TOut_ChC</th>\n",
       "      <th>h_TOut_ChF</th>\n",
       "      <th>h_Wt_ChC</th>\n",
       "      <th>h_Wt_ChF</th>\n",
       "      <th>h_Wt_Ch1</th>\n",
       "      <th>h_Wt_Ch2</th>\n",
       "      <th>h_VlvBpss_Snd</th>\n",
       "      <th>h_TCool_Snd</th>\n",
       "      <th>h_CapCool_Snd1</th>\n",
       "      <th>h_CapCool_Snd2</th>\n",
       "      <th>h_CapCool_Snd3</th>\n",
       "      <th>h_THeat_Snd</th>\n",
       "      <th>h_Wint_ChF</th>\n",
       "      <th>h_Wint_ChC</th>\n",
       "      <th>h_CapHeat_Snd1</th>\n",
       "      <th>h_CapHeat_Snd2</th>\n",
       "      <th>h_CapHeat_Snd3</th>\n",
       "      <th>h_Qr_Tot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.783603</td>\n",
       "      <td>38.338665</td>\n",
       "      <td>232.182602</td>\n",
       "      <td>235.755234</td>\n",
       "      <td>557.290039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.984179</td>\n",
       "      <td>34.337925</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.805779</td>\n",
       "      <td>0.7453</td>\n",
       "      <td>7.253334</td>\n",
       "      <td>7.061334</td>\n",
       "      <td>17.268667</td>\n",
       "      <td>17.053333</td>\n",
       "      <td>11.696458</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506667</td>\n",
       "      <td>8.760001</td>\n",
       "      <td>23.876469</td>\n",
       "      <td>23.857197</td>\n",
       "      <td>25.007097</td>\n",
       "      <td>24.050327</td>\n",
       "      <td>0.241334</td>\n",
       "      <td>1.566426</td>\n",
       "      <td>0.7453</td>\n",
       "      <td>0.805779</td>\n",
       "      <td>36.190666</td>\n",
       "      <td>36.192665</td>\n",
       "      <td>28599.992188</td>\n",
       "      <td>26129.994141</td>\n",
       "      <td>4400.000488</td>\n",
       "      <td>29349.998047</td>\n",
       "      <td>99.79792</td>\n",
       "      <td>6.575214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.954935</td>\n",
       "      <td>22.497906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>35433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 00:15:00</td>\n",
       "      <td>0.926969</td>\n",
       "      <td>38.338665</td>\n",
       "      <td>197.970230</td>\n",
       "      <td>113.384056</td>\n",
       "      <td>372.547760</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>26.805664</td>\n",
       "      <td>34.337925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>18.049334</td>\n",
       "      <td>18.143999</td>\n",
       "      <td>11.142512</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.783334</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>23.743521</td>\n",
       "      <td>23.482405</td>\n",
       "      <td>24.844606</td>\n",
       "      <td>24.014942</td>\n",
       "      <td>0.847523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.625999</td>\n",
       "      <td>32.770664</td>\n",
       "      <td>163366.671875</td>\n",
       "      <td>193396.765625</td>\n",
       "      <td>18550.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.00000</td>\n",
       "      <td>6.811282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588573</td>\n",
       "      <td>22.497906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>35441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 00:30:00</td>\n",
       "      <td>0.793163</td>\n",
       "      <td>38.455196</td>\n",
       "      <td>211.676941</td>\n",
       "      <td>236.968918</td>\n",
       "      <td>469.299347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.055836</td>\n",
       "      <td>34.337925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>17.046000</td>\n",
       "      <td>18.285332</td>\n",
       "      <td>11.005099</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>45.333332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.583336</td>\n",
       "      <td>34.330002</td>\n",
       "      <td>28.553656</td>\n",
       "      <td>25.254684</td>\n",
       "      <td>26.629427</td>\n",
       "      <td>24.510832</td>\n",
       "      <td>4.030735</td>\n",
       "      <td>2.542509</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.247997</td>\n",
       "      <td>32.559998</td>\n",
       "      <td>103306.765625</td>\n",
       "      <td>137973.359375</td>\n",
       "      <td>218650.000000</td>\n",
       "      <td>96750.000000</td>\n",
       "      <td>125.00000</td>\n",
       "      <td>7.024103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.288696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>35442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 00:45:00</td>\n",
       "      <td>0.860073</td>\n",
       "      <td>38.688263</td>\n",
       "      <td>206.066818</td>\n",
       "      <td>298.481995</td>\n",
       "      <td>570.994995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.266325</td>\n",
       "      <td>34.337925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>13.052667</td>\n",
       "      <td>16.986666</td>\n",
       "      <td>10.627213</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.220001</td>\n",
       "      <td>66.606667</td>\n",
       "      <td>28.101223</td>\n",
       "      <td>24.247793</td>\n",
       "      <td>29.106291</td>\n",
       "      <td>24.254900</td>\n",
       "      <td>4.101076</td>\n",
       "      <td>3.683874</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.989998</td>\n",
       "      <td>32.559998</td>\n",
       "      <td>73883.296875</td>\n",
       "      <td>102829.898438</td>\n",
       "      <td>247150.000000</td>\n",
       "      <td>214850.000000</td>\n",
       "      <td>125.00000</td>\n",
       "      <td>7.173333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.273752</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>35443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>0.812257</td>\n",
       "      <td>38.688263</td>\n",
       "      <td>193.984100</td>\n",
       "      <td>292.789215</td>\n",
       "      <td>563.804016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.605207</td>\n",
       "      <td>34.330490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>10.656666</td>\n",
       "      <td>15.002000</td>\n",
       "      <td>10.664143</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.046669</td>\n",
       "      <td>66.820000</td>\n",
       "      <td>28.108610</td>\n",
       "      <td>24.004572</td>\n",
       "      <td>28.892099</td>\n",
       "      <td>24.561331</td>\n",
       "      <td>3.959458</td>\n",
       "      <td>3.543089</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.719997</td>\n",
       "      <td>32.242664</td>\n",
       "      <td>50396.769531</td>\n",
       "      <td>81683.398438</td>\n",
       "      <td>238550.000000</td>\n",
       "      <td>203300.000000</td>\n",
       "      <td>125.00000</td>\n",
       "      <td>7.283590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.408245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>35444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  h_Pe_Trf2  h_Pe_Trf3   h_Pe_Trf4   h_Pe_Trf5  \\\n",
       "0 2016-01-01 00:00:00   0.783603  38.338665  232.182602  235.755234   \n",
       "1 2016-01-01 00:15:00   0.926969  38.338665  197.970230  113.384056   \n",
       "2 2016-01-01 00:30:00   0.793163  38.455196  211.676941  236.968918   \n",
       "3 2016-01-01 00:45:00   0.860073  38.688263  206.066818  298.481995   \n",
       "4 2016-01-01 01:00:00   0.812257  38.688263  193.984100  292.789215   \n",
       "\n",
       "     h_Pe_Tot    h_per6  h_CtrlCool  h_CtrlHeat  h_Cap_ChF  h_Cap_ChC  \\\n",
       "0  557.290039  0.000000   26.984179   34.337925   4.266667        3.2   \n",
       "1  372.547760  0.866667   26.805664   34.337925   0.000000        0.0   \n",
       "2  469.299347  1.000000   26.055836   34.337925   0.000000        0.0   \n",
       "3  570.994995  1.000000   25.266325   34.337925   0.000000        0.0   \n",
       "4  563.804016  1.000000   25.605207   34.330490   0.000000        0.0   \n",
       "\n",
       "   h_COPInst_ChF  h_COPInst_ChC  h_Pe_ChF  h_Pe_ChC   h_Tr_ChC   h_Tr_ChF  \\\n",
       "0       0.805779         0.7453  7.253334  7.061334  17.268667  17.053333   \n",
       "1       0.000000         0.0000  0.800000  0.480000  18.049334  18.143999   \n",
       "2       0.000000         0.0000  0.800000  0.480000  17.046000  18.285332   \n",
       "3       0.000000         0.0000  0.800000  0.480000  13.052667  16.986666   \n",
       "4       0.000000         0.0000  0.800000  0.480000  10.656666  15.002000   \n",
       "\n",
       "      h_Text   h_Cap_Ch1   h_Cap_Ch2  h_COPInst_Ch1  h_COPInst_Ch2   h_Pe_Ch1  \\\n",
       "0  11.696458    1.333333    8.000000            0.0            0.0   1.506667   \n",
       "1  11.142512    8.666667    0.000000            0.0            0.0   6.783334   \n",
       "2  11.005099   86.000000   45.333332            0.0            0.0  63.583336   \n",
       "3  10.627213  100.000000  100.000000            0.0            0.0  70.220001   \n",
       "4  10.664143  100.000000  100.000000            0.0            0.0  70.046669   \n",
       "\n",
       "    h_Pe_Ch2  h_TIn_Twr1  h_TOut_Twr1  h_TIn_Twr2  h_TOut_Twr2  h_COPMq_Ch1  \\\n",
       "0   8.760001   23.876469    23.857197   25.007097    24.050327     0.241334   \n",
       "1   0.100000   23.743521    23.482405   24.844606    24.014942     0.847523   \n",
       "2  34.330002   28.553656    25.254684   26.629427    24.510832     4.030735   \n",
       "3  66.606667   28.101223    24.247793   29.106291    24.254900     4.101076   \n",
       "4  66.820000   28.108610    24.004572   28.892099    24.561331     3.959458   \n",
       "\n",
       "   h_COPMq_Ch2  h_COPMq_ChC  h_COPMq_ChF  h_TOut_ChC  h_TOut_ChF  \\\n",
       "0     1.566426       0.7453     0.805779   36.190666   36.192665   \n",
       "1     0.000000       0.0000     0.000000   33.625999   32.770664   \n",
       "2     2.542509       0.0000     0.000000   33.247997   32.559998   \n",
       "3     3.683874       0.0000     0.000000   32.989998   32.559998   \n",
       "4     3.543089       0.0000     0.000000   32.719997   32.242664   \n",
       "\n",
       "        h_Wt_ChC       h_Wt_ChF       h_Wt_Ch1       h_Wt_Ch2  h_VlvBpss_Snd  \\\n",
       "0   28599.992188   26129.994141    4400.000488   29349.998047       99.79792   \n",
       "1  163366.671875  193396.765625   18550.000000       0.000000      125.00000   \n",
       "2  103306.765625  137973.359375  218650.000000   96750.000000      125.00000   \n",
       "3   73883.296875  102829.898438  247150.000000  214850.000000      125.00000   \n",
       "4   50396.769531   81683.398438  238550.000000  203300.000000      125.00000   \n",
       "\n",
       "   h_TCool_Snd  h_CapCool_Snd1  h_CapCool_Snd2  h_CapCool_Snd3  h_THeat_Snd  \\\n",
       "0     6.575214             0.0             0.0        7.954935    22.497906   \n",
       "1     6.811282             0.0             0.0        0.588573    22.497906   \n",
       "2     7.024103             0.0             0.0        0.000000    22.288696   \n",
       "3     7.173333             0.0             0.0        0.000000    22.273752   \n",
       "4     7.283590             0.0             0.0        0.000000    22.408245   \n",
       "\n",
       "   h_Wint_ChF  h_Wint_ChC  h_CapHeat_Snd1  h_CapHeat_Snd2  h_CapHeat_Snd3  \\\n",
       "0           0           0           100.0           100.0           100.0   \n",
       "1           0           0           -25.0           -25.0           -25.0   \n",
       "2           0           0           -25.0           -25.0           -25.0   \n",
       "3           0           0           -25.0           -25.0           -25.0   \n",
       "4           0           0           -25.0           -25.0           -25.0   \n",
       "\n",
       "   h_Qr_Tot  \n",
       "0     35433  \n",
       "1     35441  \n",
       "2     35442  \n",
       "3     35443  \n",
       "4     35444  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvacs_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identifying correct missing data points/anomalies\n",
    "\n",
    "#   3.1. Dropping useless columns\n",
    "hvacs = hvacs_raw.drop(['h_Qr_Tot'], axis = 1)\n",
    "zones = zones_raw\n",
    "shows = shows_raw.drop(['s_Keycode'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   3.2. Selecting observed period from 11/09/2016 to 25/03/2018 (2011 out)\n",
    "hvacs = hvacs[(hvacs['Date'] >= '2016-09-11') & (hvacs['Date'] < '2018-03-25')] \n",
    "zones = zones[(zones['Date'] >= '2016-09-11') & (zones['Date'] < '2018-03-25')] \n",
    "shows = shows[(shows['Date'] >= '2016-09-11') & (shows['Date'] < '2018-03-25')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   3.3. Removing all-zeros features (columns)\n",
    "hvacs = hvacs.loc[:, (hvacs != 0).any(axis = 0)]\n",
    "zones = zones.loc[:, (zones != 0).any(axis = 0)]\n",
    "shows = shows.loc[:, (shows != 0).any(axis = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   3.4. Reindexing tables to 15min, filling missed records\n",
    "\n",
    "#     Removing duplicated records in 'shows'\n",
    "shows = shows.sort_values(by=['Date'])\n",
    "shows = shows.drop_duplicates(['Date'])\n",
    "\n",
    "#     Setting 'Date' as index for resampling\n",
    "hvacs = hvacs.set_index(['Date'])\n",
    "zones = zones.set_index(['Date'])\n",
    "shows = shows.set_index(['Date'])\n",
    "\n",
    "#     Re-sampling to 15min & re-filling, with linear interpolation\n",
    "idx = pd.date_range('2016-09-11', '2018-03-24 23:45', freq = '15T')\n",
    "hvacs = hvacs.reindex(idx).interpolate(method = 'linear')\n",
    "zones = zones.reindex(idx).interpolate(method = 'linear')\n",
    "shows = shows.reindex(idx).fillna(method = 'pad', limit = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thermal = abs(hvacs[['h_Wt_Ch1', 'h_Wt_Ch2', 'h_Wt_ChC', 'h_Wt_ChF']]).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(hvacs[['h_Pe_Trf2', 'h_Pe_Trf3', 'h_Pe_Trf4', 'h_Pe_Trf5', 'h_Pe_Tot',\n",
    "       'h_per6', 'h_CtrlCool', 'h_CtrlHeat', 'h_Cap_ChF', 'h_Cap_ChC',\n",
    "       'h_COPInst_ChF', 'h_COPInst_ChC', 'h_Pe_ChF', 'h_Pe_ChC', 'h_Tr_ChC',\n",
    "       'h_Tr_ChF', 'h_Text', 'h_Cap_Ch1', 'h_Cap_Ch2', 'h_COPInst_Ch1',\n",
    "       'h_COPInst_Ch2', 'h_Pe_Ch1', 'h_Pe_Ch2', 'h_TIn_Twr1', 'h_TOut_Twr1',\n",
    "       'h_TIn_Twr2', 'h_TOut_Twr2', 'h_COPMq_Ch1', 'h_COPMq_Ch2',\n",
    "       'h_COPMq_ChC', 'h_COPMq_ChF', 'h_TOut_ChC', 'h_TOut_ChF', 'h_THeat_Snd', 'h_Wint_ChF',\n",
    "       'h_Wint_ChC', 'h_CapHeat_Snd1', 'h_CapHeat_Snd2', 'h_CapHeat_Snd3']], Thermal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intercept: \\n', regr.intercept_)\n",
    "coef = pd.DataFrame([regr.coef_], columns = ['h_Pe_Trf2', 'h_Pe_Trf3', 'h_Pe_Trf4', 'h_Pe_Trf5', 'h_Pe_Tot',\n",
    "       'h_per6', 'h_CtrlCool', 'h_CtrlHeat', 'h_Cap_ChF', 'h_Cap_ChC',\n",
    "       'h_COPInst_ChF', 'h_COPInst_ChC', 'h_Pe_ChF', 'h_Pe_ChC', 'h_Tr_ChC',\n",
    "       'h_Tr_ChF', 'h_Text', 'h_Cap_Ch1', 'h_Cap_Ch2', 'h_COPInst_Ch1',\n",
    "       'h_COPInst_Ch2', 'h_Pe_Ch1', 'h_Pe_Ch2', 'h_TIn_Twr1', 'h_TOut_Twr1',\n",
    "       'h_TIn_Twr2', 'h_TOut_Twr2', 'h_COPMq_Ch1', 'h_COPMq_Ch2',\n",
    "       'h_COPMq_ChC', 'h_COPMq_ChF', 'h_TOut_ChC', 'h_TOut_ChF', 'h_THeat_Snd', 'h_Wint_ChF',\n",
    "       'h_Wint_ChC', 'h_CapHeat_Snd1', 'h_CapHeat_Snd2', 'h_CapHeat_Snd3'])\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvacs[['h_Pe_Trf2', 'h_Pe_Trf3', 'h_Pe_Trf4', 'h_Pe_Trf5', 'h_Pe_Tot',\n",
    "       'h_per6', 'h_CtrlCool', 'h_CtrlHeat', 'h_Cap_ChF', 'h_Cap_ChC',\n",
    "       'h_COPInst_ChF', 'h_COPInst_ChC', 'h_Pe_ChF', 'h_Pe_ChC', 'h_Tr_ChC',\n",
    "       'h_Tr_ChF', 'h_Text', 'h_Cap_Ch1', 'h_Cap_Ch2', 'h_COPInst_Ch1',\n",
    "       'h_COPInst_Ch2', 'h_Pe_Ch1', 'h_Pe_Ch2', 'h_TIn_Twr1', 'h_TOut_Twr1',\n",
    "       'h_TIn_Twr2', 'h_TOut_Twr2', 'h_COPMq_Ch1', 'h_COPMq_Ch2',\n",
    "       'h_COPMq_ChC', 'h_COPMq_ChF', 'h_TOut_ChC', 'h_TOut_ChF', 'h_THeat_Snd', 'h_Wint_ChF',\n",
    "       'h_Wint_ChC', 'h_CapHeat_Snd1', 'h_CapHeat_Snd2', 'h_CapHeat_Snd3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin regresion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Merging tables in one data frame, 'df'\n",
    "df = pd.DataFrame()\n",
    "df = hvacs.merge(zones, left_index = True, right_index = True)\n",
    "df = df.merge(shows, left_index = True, right_index = True)\n",
    "\n",
    "#     Recovering 'Date' as data with new name, 'tStart'\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns = {'index':'tStart'})\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Instant'] = df.index\n",
    "df = df.loc[(df.h_Text != 0), :]\n",
    "df['Interval'] = df['Instant'].shift(periods = -1) - df['Instant']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['tStart',\n",
    "     's_EventOn',\n",
    "     'h_Cap_Ch1',\n",
    "     'h_Cap_Ch2',\n",
    "     'h_Cap_ChC',\n",
    "     'h_Cap_ChF',\n",
    "     'h_Wt_Ch1',\n",
    "     'h_COPInst_Ch1',\n",
    "     'h_COPMq_Ch1',\n",
    "    'h_COPInst_Ch2',\n",
    "    'h_COPMq_Ch2',                           \n",
    "    'h_COPInst_ChC',\n",
    "    'h_COPMq_ChC',             \n",
    "    'h_COPInst_ChF',\n",
    "    'h_COPMq_ChF',\n",
    "     'h_Wt_Ch2',\n",
    "     'h_Wt_ChC',\n",
    "     'h_Wt_ChF',\n",
    "     'h_Pe_Ch1',\n",
    "     'h_Pe_Ch2',\n",
    "     'h_Pe_ChC',\n",
    "     'h_Pe_ChF']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'h_Cap_Ch1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['h_Cap_ChF'], df[ 'h_COPInst_ChF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tStart'] = df['tStart'].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['tStart'].str.contains('2016-09-11')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['h_Wt_Ch1'] <= -100) & (df['h_Cap_Ch1'] >= -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df[(abs(df['h_Wt_ChC']) > 100) & (abs(df['h_Cap_ChC']) < 1)].index\n",
    "df.drop(index , inplace=True)\n",
    "index = df[(abs(df['h_Wt_ChF']) > 100) & (abs(df['h_Cap_ChF']) < 1)].index\n",
    "df.drop(index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\n",
    "    ['h_Cap_Ch1', \n",
    "    'h_Cap_Ch2', \n",
    "    'h_Cap_ChC', \n",
    "    'h_Cap_ChF',\n",
    "     's_EventOn'\n",
    "    ]\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    [\n",
    "'s_Tr_AmbC', \n",
    "'s_Tr_CrcC', \n",
    "'s_Tr_CrcF', \n",
    "'s_Tr_FyrF', \n",
    "'s_Tr_GdF', \n",
    "'s_Tr_GoyaF', \n",
    "'s_Tr_Hal1F', \n",
    "'s_Tr_PitF', \n",
    "'s_Tr_StdsC', \n",
    "'s_Tr_StdsF', \n",
    "'s_TRet_AmbF', \n",
    "'s_TRet_StllC', \n",
    "'s_TRet_StllF', \n",
    "'z_Tr_AmbC', \n",
    "'z_Tr_GyrreC', \n",
    "'z_Tr_HalSAPAF', \n",
    "'z_Tr_OrchReheF', \n",
    "'z_Tr_Sng4', \n",
    "'z_TRet_Bllt', \n",
    "'z_TRet_Choir', \n",
    "'z_TRet_CrcC', \n",
    "'z_TRet_CrcF', \n",
    "'z_TRet_Hal6F', \n",
    "'z_TRet_OffiF', \n",
    "'z_TRet_R14', \n",
    "'z_TRet_Store', \n",
    "'z_TRet_Tech'  \n",
    "    ]\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build model variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#   4.1. Controlled variables (inputs)\n",
    "\n",
    "#  ****************************************\n",
    "#  ******  Time for the OM to start  ******\n",
    "#  ****************************************\n",
    "tStart = pd.DataFrame()\n",
    "tStart = df['tStart']\n",
    "\n",
    "#  ****************************************************************\n",
    "#  ******  Chiller capacity (Power minus sign when cooling)  ******\n",
    "#  ****************************************************************\n",
    "###Revisado\n",
    "Cap1 = pd.DataFrame()\n",
    "Cap2 = pd.DataFrame()\n",
    "Cap3 = pd.DataFrame()\n",
    "Cap4 = pd.DataFrame()\n",
    "\n",
    "df[\n",
    "    ['h_Cap_Ch1', \n",
    "    'h_Cap_Ch2', \n",
    "    'h_Cap_ChC', \n",
    "    'h_Cap_ChF'\n",
    "    ]\n",
    "] = -df[\n",
    "    ['h_Cap_Ch1', \n",
    "     'h_Cap_Ch2', \n",
    "     'h_Cap_ChC', \n",
    "     'h_Cap_ChF'\n",
    "    ]\n",
    "]\n",
    "df.loc[df['h_Wint_ChC'] == 1, 'h_Cap_ChC'] = -df.loc[df['h_Wint_ChC'] == 1, 'h_Cap_ChC']\n",
    "df.loc[df['h_Wint_ChF'] == 1, 'h_Cap_ChF'] = -df.loc[df['h_Wint_ChF'] == 1, 'h_Cap_ChF']\n",
    "\n",
    "[Cap1, Cap2, Cap3, Cap4] = [df['h_Cap_Ch1'], df['h_Cap_Ch2'], df['h_Cap_ChC'], df['h_Cap_ChF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['h_Wint_ChC'] == 1, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#   4.2. Uncontrolled variables (Context)\n",
    "\n",
    "# ************************************\n",
    "# ******  Outdoors temperature  ******\n",
    "# ************************************\n",
    "#     h_Text is incomplete, but it is the most informative.\n",
    "TExt = pd.DataFrame()\n",
    "TExt = df['h_Text']\n",
    "\n",
    "# *****************************************************************\n",
    "# ******  Setpoint to 22 in the winter and 24 in the summer  ****** \n",
    "# *****************************************************************\n",
    "#     Data visualization shows room temperature always at 23 or 24\n",
    "T0 = pd.DataFrame()\n",
    "df['SP'] = 23.5\n",
    "T0 = df['SP']\n",
    "\n",
    "T0_in = pd.DataFrame()\n",
    "T0_in = T0\n",
    "\n",
    "# *****************************************************\n",
    "# ******  Occupants, 440 emmployees, 1746 seats  ****** \n",
    "# *****************************************************\n",
    "#     Initial approach for events to have 1700 people when start\n",
    "Capacity = 1700\n",
    "People = pd.DataFrame()\n",
    "df['people'] = 0\n",
    "df.loc[df['s_EventOn'] > 0, 'people'] = Capacity\n",
    "People = df['people']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raul\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Raul\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\pandas\\core\\frame.py:2986: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._where(-key, value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#   4.3. Manipulated variables (Outputs)\n",
    "\n",
    "# ***************************************************************\n",
    "# ******  Indoors temperature (shifted s steps to future)  ******\n",
    "# ***************************************************************\n",
    "#     Selecting room temperatures from different table to average\n",
    "Tr = pd.DataFrame()\n",
    "Tr = df[\n",
    "    [\n",
    "'s_Tr_AmbC', \n",
    "'s_Tr_CrcC', \n",
    "'s_Tr_CrcF', \n",
    "'s_Tr_FyrF', \n",
    "'s_Tr_GdF', \n",
    "'s_Tr_GoyaF', \n",
    "'s_Tr_Hal1F', \n",
    "'s_Tr_PitF', \n",
    "'s_Tr_StdsC', \n",
    "'s_Tr_StdsF', \n",
    "'s_TRet_AmbF', \n",
    "'s_TRet_StllC', \n",
    "'s_TRet_StllF', \n",
    "'z_Tr_AmbC', \n",
    "'z_Tr_GyrreC', \n",
    "'z_Tr_HalSAPAF', \n",
    "'z_Tr_OrchReheF', \n",
    "'z_Tr_Sng4', \n",
    "'z_TRet_Bllt', \n",
    "'z_TRet_Choir', \n",
    "'z_TRet_CrcC', \n",
    "'z_TRet_CrcF', \n",
    "'z_TRet_Hal6F', \n",
    "'z_TRet_OffiF', \n",
    "'z_TRet_R14', \n",
    "'z_TRet_Store', \n",
    "'z_TRet_Tech'  \n",
    "    ]\n",
    "]\n",
    "\n",
    "#     Getting the average every 15min (excluding NaNs & 0s)\n",
    "Tr[Tr <= 0] = np.NaN\n",
    "Tr = Tr.mean(axis = 1, skipna = True)\n",
    "\n",
    "#     Smoothing outliers with the moving average\n",
    "Tr_stats = Tr.describe()\n",
    "iqr = Tr_stats['75%'] - Tr_stats['25%'] \n",
    "iqr_up = Tr_stats['75%'] + 1.5 * iqr\n",
    "iqr_down = Tr_stats['25%'] - 1.5 * iqr\n",
    "Tr[(Tr <= iqr_down) | (Tr >= iqr_up)] = Tr.rolling(window=10).mean()\n",
    "\n",
    "#     Tr_in: current Tr value  \n",
    "Tr_in = pd.DataFrame()\n",
    "Tr_in = Tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38599.000000\n",
       "mean        22.944224\n",
       "std          2.237025\n",
       "min         16.119646\n",
       "25%         21.591791\n",
       "50%         22.955385\n",
       "75%         24.405027\n",
       "max         28.279452\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#   4.4. Target variables (for MO fitness).\n",
    "\n",
    "#     Shifting 's' steps backwards to go 1 step ahead\n",
    "s = 1\n",
    "\n",
    "# **********************************************************************\n",
    "# ****  Comfort, difference between ambient temperature & setpoint  **** \n",
    "# **********************************************************************\n",
    "#     Tr_out: Result, shifting backwards 's' steps to the future\n",
    "Tr_out = pd.DataFrame()\n",
    "Tr_out = Tr.shift(periods = -s)\n",
    "\n",
    "T0_out = pd.DataFrame()\n",
    "T0_out = T0.shift(periods = -s)\n",
    "\n",
    "Comfort = pd.DataFrame()\n",
    "Comfort = Tr_out - T0_out\n",
    "\n",
    "# *************************************************\n",
    "# ******  Consumed electrical energy [KW.h]  ****** \n",
    "# *************************************************\n",
    "Energy = pd.DataFrame()\n",
    "df['Power'] = df[\n",
    "    ['h_Pe_Ch1', \n",
    "     'h_Pe_Ch2', \n",
    "     'h_Pe_ChC', \n",
    "     'h_Pe_ChF'\n",
    "    ]\n",
    "].sum(axis = 1)\n",
    "#Energy = df['Power'].shift(periods = -s) * 0.25\n",
    "Energy = df['Power'] * 0.25\n",
    "# ***************************************\n",
    "# ******  Energy Cost of HVAC [€]  ****** \n",
    "# ***************************************\n",
    "#     There is only info on lowest cost period, 0.06 (P6) & 0.08 (no P6)\n",
    "Cost = pd.DataFrame()\n",
    "df['Cost'] = 0.08\n",
    "df.loc[df['h_per6'] == 1, 'Cost'] = 0.06\n",
    "#Cost = df['Cost'].shift(periods = -s)\n",
    "Cost = df['Cost']\n",
    "Cost = Cost.mul(Energy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************\n",
    "# ******  multi-HVAC performance, COP/EER [KW/KW]  ******\n",
    "# *******************************************************\n",
    "\n",
    "\n",
    "\n",
    "COP = pd.DataFrame()\n",
    "df[\n",
    "    ['h_Wt_Ch1', \n",
    "     'h_Wt_Ch2', \n",
    "     'h_Wt_ChC', \n",
    "     'h_Wt_ChF'\n",
    "    ]\n",
    "] = -df[\n",
    "    ['h_Wt_Ch1', \n",
    "     'h_Wt_Ch2', \n",
    "     'h_Wt_ChC', \n",
    "     'h_Wt_ChF'\n",
    "    ]\n",
    "]\n",
    "df.loc[df['h_Wint_ChC'] == 1, 'h_Wt_ChC'] = -df.loc[df['h_Wint_ChC'] == 1, 'h_Wt_ChC']\n",
    "df.loc[df['h_Wint_ChF'] == 1, 'h_Wt_ChF'] = -df.loc[df['h_Wint_ChF'] == 1, 'h_Wt_ChF']\n",
    "\n",
    "\n",
    "\n",
    "df['Thermal'] = abs(df[['h_Wt_Ch1', 'h_Wt_Ch2', 'h_Wt_ChC', 'h_Wt_ChF']]).sum(axis = 1)\n",
    "#df['Thermal'] = df['Thermal'] / 859.845227859\n",
    "df['Thermal'] = df['Thermal'] / 1000\n",
    "'''\n",
    "df['COP1'] = 0\n",
    "df['COP2'] = 0\n",
    "df['COPC'] = 0\n",
    "df['COPF'] = 0\n",
    "\n",
    "\n",
    "df.loc[df['h_Pe_Ch1'] != 0, 'COP1'] = abs(df.loc[df['h_Pe_Ch1'] != 0, 'h_Wt_Ch1']) / (1000*df.loc[df['h_Pe_Ch1'] != 0, 'h_Pe_Ch1'])\n",
    "df.loc[df['h_Pe_Ch2'] != 0, 'COP2'] = abs(df.loc[df['h_Pe_Ch1'] != 0, 'h_Wt_Ch1']) / (1000*df.loc[df['h_Pe_Ch1'] != 0, 'h_Pe_Ch1'])\n",
    "df.loc[df['h_Pe_ChC'] != 0, 'COPC'] = abs(df.loc[df['h_Pe_Ch1'] != 0, 'h_Wt_Ch1']) / (1000*df.loc[df['h_Pe_Ch1'] != 0, 'h_Pe_Ch1'])\n",
    "df.loc[df['h_Pe_ChF'] != 0, 'COPF'] = abs(df.loc[df['h_Pe_Ch1'] != 0, 'h_Wt_Ch1']) / (1000*df.loc[df['h_Pe_Ch1'] != 0, 'h_Pe_Ch1'])\n",
    "                \n",
    " '''               \n",
    "df.loc[df['Power'] != 0, 'COP'] = df.loc[df['Power'] != 0, 'Thermal'] /df.loc[df['Power'] != 0, 'Power']\n",
    "#COP = df['COP'].shift(periods = -s)\n",
    "COP = df['COP']\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(abs(df['h_Cap_ChC']) < 2) & (abs(df['h_Wt_ChC']) > 200), ['h_Cap_ChC', 'h_Wt_ChC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df[(df['h_Wt_Ch1'] <= -100) & (df['h_Cap_Ch1'] >= -1)].index\n",
    "df.drop(index , inplace=True)\n",
    "index = df[(df['h_Wt_Ch2'] <= -100) & (df['h_Cap_Ch2'] >= -1)].index\n",
    "df.drop(index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[47000:47010,['h_Cap_Ch1', 'h_Cap_Ch2', 'h_Cap_ChC', 'h_Cap_ChF', 'h_Wt_Ch1', 'h_Wt_Ch2', 'h_Wt_ChC', 'h_Wt_ChF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor = (df['h_Wt_ChC']/1000)/df['h_Pe_ChC']\n",
    "print(valor)\n",
    "plt.scatter(df['h_Cap_ChC'], (df['h_Wt_ChC']/1000)/df['h_Pe_ChC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chillers = df[['h_Cap_Ch1','h_Cap_Ch2', 'h_Cap_ChC','h_Cap_ChF']].sum(axis = 1)\n",
    "plt.scatter(chillers, df['Thermal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['h_Cap_ChC'] > 0, ['h_Cap_Ch1', 'h_Cap_Ch2', 'h_Cap_ChC', 'h_Cap_ChF','h_Wt_Ch1',      'h_Wt_Ch2',      'h_Wt_ChC',      'h_Wt_ChF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "pca = pca.fit(prediction.values)\n",
    "pca.get_params'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.17. Multilayer Perceptron. COP. Graphical fitness\n",
    "plt.scatter(df['COP'],Energy)\n",
    "plt.title('Multi-HVAC COP')\n",
    "plt.xlabel('Power')\n",
    "plt.ylabel('COP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COP.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Data frames declarations\n",
    "prediction = pd.DataFrame()\n",
    "predictors = pd.DataFrame()\n",
    "target = pd.DataFrame()\n",
    "results = pd.DataFrame()\n",
    "\n",
    "prediction['Cap1'] = Cap1\n",
    "prediction['Cap2'] = Cap2\n",
    "prediction['Cap3'] = Cap3\n",
    "prediction['Cap4'] = Cap4\n",
    "\n",
    "prediction['TExt'] = TExt\n",
    "prediction['T0'] = T0_in\n",
    "prediction['People'] = People\n",
    "prediction['Tr_in'] = Tr_in\n",
    "\n",
    "prediction['Tr_out'] = Tr_out\n",
    "prediction['Comfort'] = Comfort\n",
    "prediction['Energy'] = Energy\n",
    "prediction['Cost'] = Cost\n",
    "prediction['COP'] = COP\n",
    "\n",
    "prediction['year'] = tStart.dt.year\n",
    "prediction['month'] = tStart.dt.month\n",
    "prediction['day'] = tStart.dt.day\n",
    "prediction['hour'] = tStart.dt.hour\n",
    "prediction['minute'] = tStart.dt.minute\n",
    "\n",
    "prediction['Instant'] = prediction.index\n",
    "prediction = prediction.loc[(prediction.TExt != 0), :]\n",
    "prediction['Interval'] = prediction['Instant'].shift(periods = -s) - prediction['Instant']\n",
    "\n",
    "prediction = prediction.drop(prediction.tail(s).index)\n",
    "prediction = prediction.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = prediction[prediction['Interval'] < 10000]\n",
    "plt.scatter(np.arange(len(prediction2)), prediction2['Interval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos COP que sea outlayer\n",
    "prediction = prediction[((prediction.COP - prediction.COP.mean()) / prediction.COP.std()).abs() < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hvac = prediction[\n",
    "    [\n",
    "        'Cap1',\n",
    "        'Cap2',\n",
    "        'Cap3',\n",
    "        'Cap4',\n",
    "        'TExt',\n",
    "        'T0',\n",
    "        'People',\n",
    "        'Tr_in',\n",
    "        'month',\n",
    "        'day',\n",
    "        'hour',\n",
    "        'Tr_out',\n",
    "        'Comfort',\n",
    "        'Energy',\n",
    "        'Cost',\n",
    "        'COP',\n",
    "    ]\n",
    "]\n",
    "data_hvac['COP'] = -data_hvac['COP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.17. Multilayer Perceptron. COP. Graphical fitness\n",
    "plt.scatter(np.arange(len(data_hvac)), data_hvac['COP'])\n",
    "plt.title('Multi-HVAC COP')\n",
    "plt.xlabel('Actual value')\n",
    "plt.ylabel('Prediction - MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizamos datos \n",
    "\"\"\"\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_hvac_scaled = pd.DataFrame(scaler.fit_transform(data_hvac.values), columns = data_hvac.columns)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(data_hvac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas_hvac =  data_hvac[['Cap1','Cap2','Cap3','Cap4']]\n",
    "\n",
    "scaler_hvac = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_hvac = scaler_hvac.fit(entradas_hvac.values)\n",
    "dump(scaler_hvac , open('output/scaler_hvac.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repetir por cada 1\n",
    "entradas = data_hvac[\n",
    "    [\n",
    "        'Cap1',\n",
    "        'Cap2',\n",
    "        'Cap3',\n",
    "        'Cap4',\n",
    "        'TExt',\n",
    "        'People',\n",
    "        'Tr_in',\n",
    "        'month',\n",
    "        'day',\n",
    "        'hour'\n",
    "    ]\n",
    "]\n",
    "\n",
    "scaler_entradas = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_entradas = scaler_entradas.fit(entradas.values)\n",
    "dump(scaler_entradas, open('output/scaler_entradas.pkl', 'wb'))\n",
    "entradas_normalizadas = pd.DataFrame(scaler_entradas.transform(entradas.values), columns = entradas.columns)\n",
    "\n",
    "\n",
    "salidas = data_hvac[\n",
    "    [\n",
    "        'Tr_out',\n",
    "        'Energy',\n",
    "        'COP',\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "scaler_salidas = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_salidas = scaler_salidas.fit(salidas.values)\n",
    "dump(scaler_salidas, open('output/scaler_salidas.pkl', 'wb'))\n",
    "\n",
    "salidas_normalizadas = pd.DataFrame(scaler_salidas.transform(salidas.values), columns = salidas.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(entradas_normalizadas.values, salidas_normalizadas.values, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Prediccion Temperature\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(entradas_normalizadas.values, salidas_normalizadas.values, test_size=0.3)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "        Dense(30, input_dim = 10),\n",
    "        Activation('relu'),\n",
    "        Dense(20, input_dim = 10),\n",
    "        Activation('relu'),\n",
    "        Dense(10, input_dim = 10),\n",
    "        Activation('relu'),\n",
    "        Dense(3),\n",
    "        Activation('relu')\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
    "model.fit(x_train, y_train, epochs = 9, validation_split=0.3, shuffle=True)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "\n",
    "model.save('output/modelo_hvac.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(entradas_normalizadas.values, salidas_normalizadas.values[:,2], test_size=0.3)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "        Dense(50, input_dim = 10),\n",
    "        Activation('relu'),\n",
    "        Dense(30, input_dim = 10),\n",
    "        Activation('relu'),\n",
    "        Dense(20, input_dim = 10),\n",
    "        Activation('relu'),\n",
    "        Dense(1),\n",
    "        Activation('relu')\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
    "model.fit(x_train, y_train, epochs = 20, validation_split=0.4, shuffle=True)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salidas_normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salidas_test = model.predict(x_test)\n",
    "#salidas_test_desnormalizadas = scaler_salidas.inverse_transform(salidas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salidas_desnormalizadas = scaler_salidas.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(y_test, salidas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(\"potencia HVAC3 y HVAC4\")\n",
    "ax.set_ylabel(\"Consumo\")\n",
    "j = 10\n",
    "for i in range(0, 9, 1):\n",
    "    \n",
    "    \n",
    "    entradas_modelos = scaler_entradas.transform([[-15, -12, 90, 90, 10, 2000, j, 3, 12, 20]])\n",
    "    valor_energia = scaler_salidas.inverse_transform(model.predict(entradas_modelos))[0, 0]\n",
    "    j = valor_energia\n",
    "    ax.scatter(i, valor_energia)\n",
    "    \n",
    "ax.autoscale_view(True, True)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(\"potencia HVAC3 y HVAC4\")\n",
    "ax.set_ylabel(\"Consumo\")\n",
    "j = 20\n",
    "for i in range(0, 100, 1):\n",
    "    \n",
    "    \n",
    "    entradas_modelos = scaler_entradas.transform([[0, 0, i, i, 10, 2000, 10, 3, 12, 20]])\n",
    "    print(entradas_modelos.shape)\n",
    "    valor_energia = scaler_salidas.inverse_transform(model.predict(entradas_modelos))[0, 0]\n",
    "    j = valor_energia\n",
    "    ax.scatter(i, valor_energia)\n",
    "    \n",
    "ax.autoscale_view(True, True)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas_modelos = scaler_entradas.transform([[-100, -100,i, i, 15, 1000, 20, 3, 12, 20]])\n",
    "print(entradas_modelos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(salidas_desnormalizadas[:,0], salidas_test_desnormalizadas[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(salidas_desnormalizadas[:,3], salidas_test_desnormalizadas[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reales = y_test[1]\n",
    "predecidos = model.predict(x_test)[1]\n",
    "plt.scatter(reales, predecidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(np.concatenate((x_test,y_test),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #########FIN KERAS##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.1. Multilayer Perceptron. Comfort. Model learning\n",
    "x = predictors\n",
    "y = target['Comfort']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "Comfort_fit2 = MLPRegressor(\n",
    "    hidden_layer_sizes=(25,15),\n",
    "    activation='relu',\n",
    "    solver='lbfgs',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    learning_rate_init=0.01,\n",
    "    alpha=0.01)\n",
    "Comfort_fit2.fit(x_train, y_train)\n",
    "Comfort_MLP = pd.DataFrame()\n",
    "Comfort_MLP['Actual'] = y_test\n",
    "Comfort_MLP['Predicted'] = Comfort_fit2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Guardamos el modelo\n",
    "# save the model to disk\n",
    "filename = 'comfort2_model.sav'\n",
    "pickle.dump(Comfort_fit2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.2. Multilayer Perceptron. Comfort. Graphical fitness\n",
    "plt.scatter(Comfort_MLP['Actual'], Comfort_MLP['Predicted'])\n",
    "plt.title('Comfort (ºC)')\n",
    "plt.xlabel('Actual value')\n",
    "plt.ylabel('Prediction - MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.3. Multilayer Perceptron. Comfort. Average error\n",
    "Comfort_MLP['Error'] = (Comfort_MLP['Actual'] - Comfort_MLP['Predicted'])**2\n",
    "Comfort_MLP_error = np.sqrt(Comfort_MLP.Error.sum())/len(Comfort_MLP.index)\n",
    "'The average error is ' + str(round(Comfort_MLP_error, 4)) + 'ºC'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.4. Multilayer Perceptron. Comfort. Performance\n",
    "\"The score is \" + str(round(Comfort_fit2.score(x_test, y_test) * 100,2)) + \"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.5. Multilayer Perceptron. Comfort. Variable Relevance\n",
    "#       (relevance given by the sum of squared weights in the first layer and then rooted????)\n",
    "relevance = np.zeros((11))\n",
    "for i in range(0, 10):\n",
    "    for j in range(0, 19):\n",
    "        relevance[i] = relevance[i] + mlp.coefs_[0][i][j]**2\n",
    "relevance = (relevance**.5)/(relevance**.5).sum() * 100\n",
    "Comfort_MLP_pca = pd.DataFrame(relevance, columns = ['Relevance'], index = list(predictors.columns))\n",
    "Comfort_MLP_pca.sort_values(by = 'Relevance', ascending = False, inplace = True)\n",
    "Comfort_MLP_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(x['Cap4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.6. Multilayer Perceptron. Energy. Model learning\n",
    "x = predictors[[\n",
    "        'Cap1',\n",
    "        'Cap2',\n",
    "        'Cap3',\n",
    "        'Cap4',]]\n",
    "\n",
    "y = target['Energy']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "Energy_fit2 = MLPRegressor(\n",
    "    hidden_layer_sizes=(20, 10),\n",
    "    activation='relu',\n",
    "    solver='lbfgs',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=20,\n",
    "    learning_rate_init=0.01,\n",
    "    alpha=0.01)\n",
    "Energy_fit2.fit(x_train, y_train)\n",
    "Energy_MLP = pd.DataFrame()\n",
    "Energy_MLP['Actual'] = y_test\n",
    "Energy_MLP['Predicted'] = Energy_fit2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(\"potencia HVAC3 y HVAC4\")\n",
    "ax.set_ylabel(\"Consumo\")\n",
    "for i in range(-100, 100, 1):\n",
    "    \n",
    "    entradas_modelos = np.array([-100, -100,\n",
    "                                i, i,]).reshape(1, -1)\n",
    "    valor_energia = Energy_fit2.predict(entradas_modelos)[0]\n",
    "    ax.scatter(i, valor_energia)\n",
    "    \n",
    "ax.autoscale_view(True, True)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Energy_MLP[\"Predicted\"]))\n",
    "print(len(Energy_MLP[\"Actual\"]))\n",
    "print(Energy_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo\n",
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'energy2_model.sav'\n",
    "pickle.dump(Energy_fit2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.7. Multilayer Perceptron. Energy. Graphical fitness\n",
    "plt.scatter(Energy_MLP['Actual'], Energy_MLP['Predicted'])\n",
    "plt.title('Energy (KW.h)')\n",
    "plt.xlabel('Actual value')\n",
    "plt.ylabel('Prediction - MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.8. Multilayer Perceptron. Energy. Average error\n",
    "Energy_MLP['Error'] = (Energy_MLP['Actual'] - Energy_MLP['Predicted'])**2\n",
    "Energy_MLP_e = np.sqrt(Energy_MLP.Error.sum())/len(Energy_MLP.index)\n",
    "'The average error is ' + str(round(Energy_MLP_e, 4)) + 'Kw.h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.9. Multilayer Perceptron. Energy. Performance\n",
    "\"The score is \" + str(round(Energy_fit2.score(x_test, y_test) * 100,2)) + \"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.10. Multilayer Perceptron. Energy. Variable Relevance\n",
    "#       (relevance given by the sum of squared weights in the first layer and then rooted????)\n",
    "relevance = np.zeros((11))\n",
    "for i in range(0, 10):\n",
    "    for j in range(0, 19):\n",
    "        relevance[i] = relevance[i] + mlp.coefs_[0][i][j]**2\n",
    "relevance = (relevance**.5)/(relevance**.5).sum() * 100\n",
    "Energy_MLP_pca = pd.DataFrame(relevance, columns = ['Relevance'], index = list(predictors.columns))\n",
    "Energy_MLP_pca.sort_values(by = 'Relevance', ascending = False, inplace = True)\n",
    "Energy_MLP_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.11. Multilayer Perceptron. Cost. Model learning\n",
    "x =  predictors[[\n",
    "        'Cap1',\n",
    "        'Cap2',\n",
    "        'Cap3',\n",
    "        'Cap4',]]\n",
    "\n",
    "y = target['Cost']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "Cost_fit2 = MLPRegressor(\n",
    "    hidden_layer_sizes=(30, 15, 10),\n",
    "    activation='relu',\n",
    "    solver='lbfgs',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=50,\n",
    "    learning_rate_init=0.01,\n",
    "    alpha=0.01)\n",
    "Cost_fit2.fit(x_train, y_train)\n",
    "Cost_MLP = pd.DataFrame()\n",
    "Cost_MLP['Actual'] = y_test\n",
    "Cost_MLP['Predicted'] = Cost_fit2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(\"potencia HVAC3 y HVAC4\")\n",
    "ax.set_ylabel(\"Coste\")\n",
    "for i in range(-100, 100, 1):\n",
    "    \n",
    "    entradas_modelos = np.array([-100, -100,\n",
    "                                i, i,]).reshape(1, -1)\n",
    "    valor_coste = Cost_fit2.predict(entradas_modelos)[0]\n",
    "    ax.scatter(i, valor_coste)\n",
    "    \n",
    "ax.autoscale_view(True, True)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo\n",
    "# save the model to disk\n",
    "filename = 'cost2_model.sav'\n",
    "pickle.dump(Cost_fit2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.12. Multilayer Perceptron. Cost. Graphical fitness\n",
    "plt.scatter(Cost_MLP['Actual'], Cost_MLP['Predicted'])\n",
    "plt.title('Cost (€)')\n",
    "plt.xlabel('Actual value')\n",
    "plt.ylabel('Prediction - MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.13. Multilayer Perceptron. Cost. Average error\n",
    "Cost_MLP['Error'] = (Cost_MLP['Actual'] - Cost_MLP['Predicted'])**2\n",
    "Cost_MLP_e = np.sqrt(Cost_MLP.Error.sum())/len(Cost_MLP.index)\n",
    "'The average error is ' + str(round(Cost_MLP_e, 4)) + '€'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.14. Multilayer Perceptron. Cost. Performance\n",
    "\"The score is \" + str(round(Cost_fit2.score(x_test, y_test) * 100,2)) + \"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.15. Multilayer Perceptron. Cost. Variable Relevance\n",
    "#       (relevance given by the sum of squared weights in the first layer and then rooted????)\n",
    "relevance = np.zeros((12))\n",
    "for i in range(0, 11):\n",
    "    for j in range(0, 19):\n",
    "        relevance[i] = relevance[i] + mlp.coefs_[0][i][j]**2\n",
    "relevance = (relevance**.5)/(relevance**.5).sum() * 100\n",
    "Cost_MLP_pca = pd.DataFrame(relevance, columns = ['Relevance'], index = list(predictors.columns))\n",
    "Cost_MLP_pca.sort_values(by = 'Relevance', ascending = False, inplace = True)\n",
    "Cost_MLP_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.16. Multilayer Perceptron. COP. Model learning\n",
    "x = predictors\n",
    "y = target['COP']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "COP_fit2 = MLPRegressor(\n",
    "    hidden_layer_sizes=(20,10),\n",
    "    activation='relu',\n",
    "    solver='lbfgs',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    learning_rate_init=0.01,\n",
    "    alpha=0.01)\n",
    "COP_fit2.fit(x_train, y_train)\n",
    "COP_MLP = pd.DataFrame()\n",
    "COP_MLP['Actual'] = y_test\n",
    "COP_MLP['Predicted'] = COP_fit2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo\n",
    "# save the model to disk\n",
    "filename = 'cop2_model.sav'\n",
    "pickle.dump(COP_fit2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.17. Multilayer Perceptron. COP. Graphical fitness\n",
    "plt.scatter(COP_MLP['Actual'], COP_MLP['Predicted'])\n",
    "plt.title('Multi-HVAC COP')\n",
    "plt.xlabel('Actual value')\n",
    "plt.ylabel('Prediction - MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.18. Multilayer Perceptron. COP. Average error\n",
    "COP_MLP['Error'] = (COP_MLP['Actual'] - COP_MLP['Predicted'])**2\n",
    "COP_MLP_e = np.sqrt(COP_MLP.Error.sum())/len(COP_MLP.index)\n",
    "'The average error is ' + str(round(COP_MLP_e, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.19. Multilayer Perceptron. COP. Performance\n",
    "\"The score is \" + str(round(COP_fit2.score(x_test, y_test) * 100,2)) + \"%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     5.3.20. Multilayer Perceptron. COP. Variable Relevance\n",
    "#       (relevance given by the sum of squared weights in the first layer and then rooted????)\n",
    "relevance = np.zeros((12))\n",
    "for i in range(0, 11):\n",
    "    for j in range(0, 19):\n",
    "        relevance[i] = relevance[i] + mlp.coefs_[0][i][j]**2\n",
    "relevance = (relevance**.5)/(relevance**.5).sum() * 100\n",
    "COP_MLP_pca = pd.DataFrame(relevance, columns = ['Relevance'], index = list(predictors.columns))\n",
    "COP_MLP_pca.sort_values(by = 'Relevance', ascending = False, inplace = True)\n",
    "COP_MLP_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. The mathematical model as the baseline for the data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   6.1. Physical constants\n",
    "HEAT_WATER = 4186 # J/Kg K\n",
    "DENSITY_WATER = 997 # Kg/m3\n",
    "HEAT_AIR = 1012 # J/Kg K\n",
    "DENSITY_AIR = 1.180 # Kg/m3\n",
    "GRAVITY = 9.81 # m/s2\n",
    "KELVIN = 273.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   6.2. Teatro Real Description\n",
    "\n",
    "#     6.2.1. Dimensions\n",
    "Floor_Total = 65000 # m2\n",
    "Heigth_Total = 76 # m\n",
    "Floors_Number = 16 # Floors\n",
    "Floors_above_Ground = 10 # Floors\n",
    "\n",
    "#       Deducted features\n",
    "Footprint = Floor_Total / Floors_Number\n",
    "Side1 = np.sqrt(Footprint) # m\n",
    "Side2 = Footprint / Side1 # m\n",
    "Height_Floor = Heigth_Total / Floors_Number # m\n",
    "Walls = 2 * (Side1 + Side2) * Height_Floor * Floors_above_Ground # m2\n",
    "Ceiling = Footprint # m2\n",
    "Volume = Ceiling * Height_Floor * Floors_above_Ground # m3\n",
    "\n",
    "#     6.2.2. Thermal properties, U [W/m2.K], transconductance\n",
    "U_Floor = 1.2\n",
    "U_Ceiling = 1.2\n",
    "U_Walls = 1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   6.3 Power of the sun\n",
    "WtSun = pd.DataFrame()\n",
    "WtSun = (U_Floor * Footprint + U_Ceiling * Ceiling + U_Walls * Walls) * (TExt - Tr_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   6.4. Power radiated by people\n",
    "HEAT_AVERAGE_HUMAN = 3470 # [J/Kg K]\n",
    "TEMPERATURE_SKIN = 30\n",
    "AREA_PERSON = 2 * 0.8\n",
    "BOLTZMAN = 5.67e-8 # W / m2 K4\n",
    "RADIATOR = 0.9\n",
    "\n",
    "WtPerson = AREA_PERSON * BOLTZMAN * RADIATOR \n",
    "WtPeople = pd.DataFrame()\n",
    "WtPeople = People * WtPerson * ((KELVIN + TEMPERATURE_SKIN)**4 - (KELVIN + Tr_in)**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wt_Ch1[Cap1!=0].head()\n",
    "Wt_Ch1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   6.5. Thermal Power of the Chillers\n",
    "\n",
    "# Carrier 30HXC 120-140 Chiller\n",
    "#   Wt < 510KWt (438,000KFr/h)\n",
    "#   Pe < 112KWe (115KWe sensed)\n",
    "\n",
    "# Carrier 30RQM/30RQP 402 Heat Pump\n",
    "#   Wt < 609KWth (523,000KCal/h) - 574KWth (494,000KFrig/h)\n",
    "#   Pe < 154KWe - 122KWe (164KWe sensed)\n",
    "Wtmax_Ch1 = 510000\n",
    "Wtmax_Ch2 = 510000\n",
    "Wtmax_ChC_Cool = 574000 \n",
    "Wtmax_ChF_Cool = 574000\n",
    "Wtmax_ChC_Heat = 609000 \n",
    "Wtmax_ChF_Heat = 609000\n",
    "\n",
    "Wt_Ch1 = Cap1 / 100\n",
    "Wt_Ch2 = Cap2 / 100\n",
    "Wt_ChC = Cap3 / 100\n",
    "Wt_ChF = Cap4 / 100\n",
    "\n",
    "Wt_Ch1 *= Wtmax_Ch1\n",
    "Wt_Ch2 *= Wtmax_Ch2\n",
    "Wt_ChC.loc[Wt_ChC < 0] = Wt_ChC.loc[Wt_ChC < 0] * Wtmax_ChC_Cool\n",
    "Wt_ChC.loc[Wt_ChC > 0] = Wt_ChC.loc[Wt_ChC > 0] * Wtmax_ChC_Heat\n",
    "Wt_ChF.loc[Wt_ChF < 0] = Wt_ChF.loc[Wt_ChF < 0] * Wtmax_ChF_Cool\n",
    "Wt_ChF.loc[Wt_ChF > 0] = Wt_ChF.loc[Wt_ChF > 0] * Wtmax_ChF_Heat\n",
    "\n",
    "WtChillers = Wt_Ch1 + Wt_Ch2 + Wt_ChC + Wt_ChF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   6.6 Total Thermal Power\n",
    "Wt = WtSun + WtPeople + WtChillers\n",
    "Wt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   6.7. Comfort\n",
    "Mass_Air = DENSITY_AIR * Volume\n",
    "\n",
    "#     Qt = ∫Wt dt, Wt ≈ constant in 15min,\n",
    "Qt = Wt * 0.25 *3600\n",
    "\n",
    "Tr_out_math = Tr_in + Qt / (HEAT_AIR * Mass_Air)\n",
    "Comfort_math = Tr_out_math - T0\n",
    "Comfort_math.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.\n",
    "dif_Comfort = Comfort_math - Comfort\n",
    "[mean_dComfort, std_dComfort] = [dif_Comfort.mean(), dif_Comfort.std()]\n",
    "[mean_dComfort, std_dComfort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_Tr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
